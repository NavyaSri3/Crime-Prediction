{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\n"
     ]
    }
   ],
   "source": [
    "cd D:\\project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navya\\Downloads\\kaggle-cervical_cancer_screening-master\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Navya\\Downloads\\kaggle-cervical_cancer_screening-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Navya\\\\Downloads\\\\kaggle-cervical_cancer_screening-master'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "\n",
    "# Internal Imports\n",
    "from utilities import inout\n",
    "from utilities import image_manipulation as imanip\n",
    "from models import model as mod\n",
    "from utilities import miscellaneous as misc\n",
    "\n",
    "############# User Defined Variables\n",
    "\n",
    "n_labels = 3\n",
    "batch_size = 100\n",
    "image_shape = (256,256,3)\n",
    "\n",
    "conv_shapes=[(3,3),(5,5)]\n",
    "conv_depths=[10,12,14,16,20]\n",
    "dense_shapes=[200,70,3]\n",
    "image_shape=(256,256,3)\n",
    "ones_depth=25\n",
    "\n",
    "training_csv = 'csvs/train_set.csv'\n",
    "valid_csv = 'csvs/valid_set.csv'\n",
    "\n",
    "\n",
    "############# Read in Data\n",
    "X_train_paths, y_train = inout.get_split_data(training_csv)\n",
    "X_valid_paths, y_valid = inout.get_split_data(valid_csv)\n",
    "n_labels = max(y_train)+1\n",
    "\n",
    "y_train = imanip.one_hot_encode(y_train, n_labels)\n",
    "y_valid = imanip.one_hot_encode(y_valid, n_labels)\n",
    "\n",
    "\n",
    "############### Image Generator Parameters\n",
    "\n",
    "add_random_augmentations = True\n",
    "resize_dims = None\n",
    "\n",
    "\n",
    "n_train_samples = len(X_train_paths)\n",
    "train_steps_per_epoch = misc.get_steps(n_train_samples,batch_size,n_augs=1)\n",
    "\n",
    "n_valid_samples = len(X_valid_paths)\n",
    "valid_steps_per_epoch = misc.get_steps(n_valid_samples,batch_size,n_augs=0)\n",
    "\n",
    "train_generator = inout.image_generator(X_train_paths,\n",
    "                                  y_train,\n",
    "                                  batch_size,\n",
    "                                  resize_dims=resize_dims,\n",
    "                                  randomly_augment=add_random_augmentations)\n",
    "valid_generator = inout.image_generator(X_valid_paths, y_valid,\n",
    "                                  batch_size, resize_dims=resize_dims,\n",
    "\t\t\t\t\t\t\t\t  rand_order=False)\n",
    "\n",
    "\n",
    "\n",
    "############ Training Section\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "\n",
    "inputs, outs = mod.cnn_model_1x1(conv_shapes, conv_depths, dense_shapes, image_shape, n_labels,ones_depth)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outs)\n",
    "\n",
    "adam_opt = optimizers.Adam(lr=.0001)\n",
    "for i in range(20):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "    history = model.fit_generator(train_generator, train_steps_per_epoch, epochs=1,\n",
    "                        validation_data=valid_generator,validation_steps=valid_steps_per_epoch, max_q_size=1)\n",
    "    model.save('./weights/model_1x1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Imports\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "\n",
    "# Internal Imports\n",
    "from utilities import inout\n",
    "from utilities import image_manipulation as imanip\n",
    "from models import model as mod\n",
    "from utilities import miscellaneous as misc\n",
    "\n",
    "############# User Defined Variables\n",
    "\n",
    "n_labels = 3\n",
    "batch_size = 100\n",
    "image_shape = (256,256,3)\n",
    "\n",
    "conv_shapes=[(3,3),(5,5)]\n",
    "conv_depths=[10,12,14,16,20]\n",
    "dense_shapes=[200,70,3]\n",
    "image_shape=(256,256,3)\n",
    "ones_depth=25\n",
    "\n",
    "training_csv = 'csvs/train_set.csv'\n",
    "valid_csv = 'csvs/valid_set.csv'\n",
    "\n",
    "\n",
    "############# Read in Data\n",
    "X_train_paths, y_train = inout.get_split_data(training_csv)\n",
    "X_valid_paths, y_valid = inout.get_split_data(valid_csv)\n",
    "n_labels = max(y_train)+1\n",
    "\n",
    "y_train = imanip.one_hot_encode(y_train, n_labels)\n",
    "y_valid = imanip.one_hot_encode(y_valid, n_labels)\n",
    "\n",
    "\n",
    "############### Image Generator Parameters\n",
    "\n",
    "add_random_augmentations = True\n",
    "resize_dims = None\n",
    "\n",
    "\n",
    "n_train_samples = len(X_train_paths)\n",
    "train_steps_per_epoch = misc.get_steps(n_train_samples,batch_size,n_augs=1)\n",
    "\n",
    "n_valid_samples = len(X_valid_paths)\n",
    "valid_steps_per_epoch = misc.get_steps(n_valid_samples,batch_size,n_augs=0)\n",
    "\n",
    "train_generator = inout.image_generator(X_train_paths,\n",
    "                                  y_train,\n",
    "                                  batch_size,\n",
    "                                  resize_dims=resize_dims,\n",
    "                                  randomly_augment=add_random_augmentations)\n",
    "valid_generator = inout.image_generator(X_valid_paths, y_valid,\n",
    "                                  batch_size, resize_dims=resize_dims,\n",
    "\t\t\t\t\t\t\t\t  rand_order=False)\n",
    "\n",
    "\n",
    "\n",
    "############ Training Section\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "\n",
    "inputs, outs = mod.cnn_model_1x1(conv_shapes, conv_depths, dense_shapes, image_shape, n_labels,ones_depth)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outs)\n",
    "\n",
    "adam_opt = optimizers.Adam(lr=.0001)\n",
    "for i in range(20):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "    history = model.fit_generator(train_generator, train_steps_per_epoch, epochs=1,\n",
    "                        validation_data=valid_generator,validation_steps=valid_steps_per_epoch, max_q_size=1)\n",
    "    model.save('./weights/model_1x1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
